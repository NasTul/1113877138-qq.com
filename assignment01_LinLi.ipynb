{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Preprocessing and Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: Lin Li\n",
    "\n",
    "Student ID: 964046"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Info\n",
    "\n",
    "<b>Due date</b>: Sunday, 5 Apr 2020 5pm\n",
    "\n",
    "<b>Submission method</b>: Canvas submission\n",
    "\n",
    "<b>Submission materials</b>: completed copy of this iPython notebook\n",
    "\n",
    "<b>Late submissions</b>: -20% per day (both week and weekend days counted)\n",
    "\n",
    "<b>Marks</b>: 10% of mark for class (with 9% on correctness + 1% on quality and efficiency of your code)\n",
    "\n",
    "<b>Materials</b>: See [Using Jupyter Notebook and Python page](https://canvas.lms.unimelb.edu.au/courses/17601/pages/using-jupyter-notebook-and-python?module_item_id=1678430) on Canvas (under Modules>Resources) for information on the basic setup required for this class, including an iPython notebook viewer and the python packages NLTK, Numpy, Scipy, Matplotlib, Scikit-Learn, and Gensim. In particular, if you are not using a lab computer which already has it installed, we recommend installing all the data for NLTK, since you will need various parts of it to complete this assignment. You can also use any Python built-in packages, but do not use any other 3rd party packages (the packages listed above are all fine to use); if your iPython notebook doesn't run on the marker's machine, you will lose marks. <b> You should use Python 3</b>.  \n",
    "\n",
    "To familiarize yourself with NLTK, here is a free online book:  Steven Bird, Ewan Klein, and Edward Loper (2009). <a href=http://nltk.org/book>Natural Language Processing with Python</a>. O'Reilly Media Inc. You may also consult the <a href=https://www.nltk.org/api/nltk.html>NLTK API</a>.\n",
    "\n",
    "<b>Evaluation</b>: Your iPython notebook should run end-to-end without any errors in a reasonable amount of time, and you must follow all instructions provided below, including specific implementation requirements and instructions for what needs to be printed (please avoid printing output we don't ask for). You should edit the sections below where requested, but leave the rest of the code as is. You should leave the output from running your code in the iPython notebook you submit, to assist with marking. The amount each section is worth is given in parenthesis after the instructions. \n",
    "\n",
    "You will be marked not only on the correctness of your methods, but also the quality and efficency of your code: in particular, you should be careful to use Python built-in functions and operators when appropriate and pick descriptive variable names that adhere to <a href=\"https://www.python.org/dev/peps/pep-0008/\">Python style requirements</a>. If you think it might be unclear what you are doing, you should comment your code to help the marker make sense of it.\n",
    "\n",
    "<b>Updates</b>: Any major changes to the assignment will be announced via Canvas. Minor changes and clarifications will be announced on the discussion board; we recommend you check it regularly.\n",
    "\n",
    "<b>Academic misconduct</b>: For most people, collaboration will form a natural part of the undertaking of this homework, and we encourge you to discuss it in general terms with other students. However, this ultimately is still an individual task, and so reuse of code or other instances of clear influence will be considered cheating. We will be checking submissions for originality and will invoke the Universityâ€™s <a href=\"http://academichonesty.unimelb.edu.au/policy.html\">Academic Misconduct policy</a> where inappropriate levels of collusion or plagiarism are deemed to have taken place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this homework, you'll be working with a collection tweets. The task is to classify whether a tweet constitutes a rumour event. This homework involves writing code to preprocess data and perform text classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing (5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**: Run the code below to download the tweet corpus for the assignment. Note: the download may take some time. **No implementation is needed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. File downloaded: rumour-data.tgz\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "fname = 'rumour-data.tgz'\n",
    "data_dir = os.path.splitext(fname)[0] #'rumour-data'\n",
    "\n",
    "my_file = Path(fname)\n",
    "if not my_file.is_file():\n",
    "    url = \"https://github.com/jhlau/jhlau.github.io/blob/master/files/rumour-data.tgz?raw=true\"\n",
    "    r = requests.get(url)\n",
    "\n",
    "    #Save to the current directory\n",
    "    with open(fname, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "        \n",
    "print(\"Done. File downloaded:\", my_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**: Run the code to extract the zip file. Note: the extraction may take a minute or two. **No implementation is needed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction done.\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "\n",
    "#decompress rumour-data.tgz\n",
    "tar = tarfile.open(fname, \"r:gz\")\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "\n",
    "#remove superfluous files (e.g. .DS_store)\n",
    "extra_files = []\n",
    "for r, d, f in os.walk(data_dir):\n",
    "    for file in f:\n",
    "        if (file.startswith(\".\")):\n",
    "            extra_files.append(os.path.join(r, file))\n",
    "for f in extra_files:\n",
    "    os.remove(f)\n",
    "\n",
    "print(\"Extraction done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 (1.0 mark)\n",
    "\n",
    "**Instructions**: The corpus data is in the *rumour-data* folder. It contains 2 sub-folders: *non-rumours* and *rumours*. As the names suggest, *rumours* contains all rumour-propagating tweets, while *non-rumours* has normal tweets. Within  *rumours* and *non-rumours*, you'll find some sub-folders, each named with an ID. Each of these IDs constitutes an 'event', where an event is defined as consisting a **source tweet** and its **reactions**.\n",
    "\n",
    "An illustration of the folder structure is given below:\n",
    "\n",
    "    rumour-data\n",
    "        - rumours\n",
    "            - 498254340310966273\n",
    "                - reactions\n",
    "                    - 498254340310966273.json\n",
    "                    - 498260814487642112.json\n",
    "                - source-tweet\n",
    "                    - 498254340310966273.json\n",
    "        - non-rumours\n",
    "\n",
    "Now we need to gather the tweet messages for rumours and non-rumour events. As the individual tweets are stored in json format, we need to use a json parser to parse and collect the actual tweet message. The function `get_tweet_text_from_json(file_path)` is provided to do that.\n",
    "\n",
    "**Task**: Complete the `get_events(event_dir)` function. The function should return **a list of events** for a particular class of tweets (e.g. rumours), and each event should contain the source tweet message and all reaction tweet messages.\n",
    "\n",
    "**Check**: Use the assertion statements in *\"For your testing\"* below for the expected output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rumour events = 500\n",
      "Number of non-rumour events = 1000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def get_tweet_text_from_json(file_path):\n",
    "    with open(file_path) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        return data[\"text\"]\n",
    "    \n",
    "def get_events(event_dir):\n",
    "    \n",
    "    \n",
    "\n",
    "    event_list = []\n",
    "    for event in sorted(os.listdir(event_dir)):\n",
    "        ###\n",
    "        # Your answer BEGINS HERE\n",
    "        ###\n",
    "        sub_event = []\n",
    "        reactions_dir = event_dir+\"/\"+event+\"/reactions/\"\n",
    "        source_tweet_dir = event_dir+\"/\"+event+\"/source-tweet/\"\n",
    "        \n",
    "        #Extract the file information from the reactions and source-tweet folders to event_list.\n",
    "        for reaction_file in os.listdir(reactions_dir):\n",
    "            file_path = reactions_dir+reaction_file\n",
    "            text = get_tweet_text_from_json(file_path)\n",
    "            sub_event.append(text)\n",
    "        for source_tweet_file in os.listdir(source_tweet_dir):\n",
    "            file_path = source_tweet_dir+source_tweet_file\n",
    "            text = get_tweet_text_from_json(file_path)\n",
    "            sub_event.append(text)\n",
    "        event_list.append(sub_event)\n",
    "        \n",
    "\n",
    "        ###\n",
    "        # Your answer ENDS HERE\n",
    "        ###\n",
    "\n",
    "        \n",
    "    return event_list\n",
    "    \n",
    "#a list of events, and each event is a list of tweets (source tweet + reactions)    \n",
    "rumour_events = get_events(os.path.join(data_dir, \"rumours\"))\n",
    "nonrumour_events = get_events(os.path.join(data_dir, \"non-rumours\"))\n",
    "\n",
    "print(\"Number of rumour events =\", len(rumour_events))\n",
    "print(\"Number of non-rumour events =\", len(nonrumour_events))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For your testing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(rumour_events) == 500)\n",
    "assert(len(nonrumour_events) == 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 (1.0 mark)\n",
    "\n",
    "**Instructions**: Next we need to preprocess the collected tweets to create a bag-of-words representation. The preprocessing steps required here are: (1) tokenize each tweet into individual word tokens (using NLTK `TweetTokenizer`); and (2) remove stopwords (based on NLTK `stopwords`).\n",
    "\n",
    "**Task**: Complete the `preprocess_events(event)` function. The function takes **a list of events** as input, and returns **a list of preprocessed events**. Each preprocessed event should have a dictionary of words and frequencies.\n",
    "\n",
    "**Check**: Use the assertion statements in *\"For your testing\"* below for the expected output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of preprocessed rumour events = 500\n",
      "Number of preprocessed non-rumour events = 1000\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "\n",
    "tt = TweetTokenizer()\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def preprocess_events(events):\n",
    "    ###\n",
    "    # Your answer BEGINS HERE\n",
    "    ###\n",
    "    preprocess_events=[]\n",
    "    \n",
    "    #Extract the token, from each event and count the number of each token\n",
    "    for event in events:\n",
    "        token_word_dct=defaultdict(int)\n",
    "        for sentence in event:\n",
    "            for token_word in tt.tokenize(sentence):\n",
    "                #some words like \"The\" not in stopwords, but \"the\" is in, so use fuction lower().\n",
    "                if token_word.lower() not in stopwords:\n",
    "                    token_word_dct[token_word]+=1\n",
    "        \n",
    "        preprocess_events.append(token_word_dct)\n",
    "        \n",
    "    return preprocess_events\n",
    "    \n",
    "    \n",
    "    \n",
    "    ###\n",
    "    # Your answer ENDS HERE\n",
    "    ###\n",
    "\n",
    "preprocessed_rumour_events = preprocess_events(rumour_events)\n",
    "preprocessed_nonrumour_events = preprocess_events(nonrumour_events)\n",
    "\n",
    "print(\"Number of preprocessed rumour events =\", len(preprocessed_rumour_events))\n",
    "print(\"Number of preprocessed non-rumour events =\", len(preprocessed_nonrumour_events))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For your testing**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(preprocessed_rumour_events) == 500)\n",
    "assert(len(preprocessed_nonrumour_events) == 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**: Hashtags (i.e. topic tags which start with #) pose an interesting tokenisation problem because they often include multiple words written without spaces or capitalization. Run the code below to collect all unique hashtags in the preprocessed data. **No implementation is needed.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hashtags = 1829\n"
     ]
    }
   ],
   "source": [
    "def get_all_hashtags(events):\n",
    "    hashtags = set([])\n",
    "    for event in events:\n",
    "        for word, frequency in event.items():\n",
    "            if word.startswith(\"#\"):\n",
    "                hashtags.add(word)\n",
    "    return hashtags\n",
    "\n",
    "hashtags = get_all_hashtags(preprocessed_rumour_events + preprocessed_nonrumour_events)\n",
    "print(\"Number of hashtags =\", len(hashtags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 (2.0 mark)\n",
    "\n",
    "**Instructions**: Our task here to tokenize the hashtags, by implementing a reversed version of the MaxMatch algorithm discussed in class, where matching begins at the end of the hashtag and progresses backwards. NLTK has a list of words that you can use for matching, see starter code below. Be careful about efficiency with respect to doing word lookups. One extra challenge you have to deal with is that the provided list of words includes only lemmas: your MaxMatch algorithm should match inflected forms by converting them into lemmas using the NLTK lemmatizer before matching. When lemmatising a word, you also need to provide the part-of-speech tag of the word. You should use `nltk.tag.pos_tag` for doing part-of-speech tagging.\n",
    "\n",
    "Note that the list of words is incomplete, and, if you are unable to make any longer match, your code should default to matching a single letter. Create a new list of tokenized hashtags (this should be a list of lists of strings) and use slicing to print out the last 20 hashtags in the list.\n",
    "\n",
    "For example, given \"#speakup\", the algorithm should produce: \\[\"#\", \"speak\", \"up\"\\]. And note that you do not need to delete the hashtag symbol (\"#\") from the tokenised outputs.\n",
    "\n",
    "**Task**: Complete the `tokenize_hashtags(hashtags)` function by implementing a reversed MaxMatch algorithm. The function takes as input **a set of hashtags**, and returns **a dictionary** where key=\"hashtag\" and value=\"a list of word tokens\".\n",
    "\n",
    "**Check**: Use the assertion statements in *\"For your testing\"* below for the expected output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('#class', ['#', 'class']), ('#bigbanks', ['#', 'big', 'banks']), ('#confused', ['#', 'confused']), ('#endreligionnow', ['#', 'end', 'religion', 'now']), ('#SpeakUP', ['#', 'Speak', 'UP']), ('#bbc', ['#', 'b', 'b', 'c']), ('#nomoreviolence', ['#', 'no', 'more', 'violence']), ('#filthy', ['#', 'filthy']), ('#Cop', ['#', 'Cop']), ('#Koran', ['#', 'Koran']), ('#MediaWatch', ['#', 'Me', 'di', 'aWatch']), ('#FergusonTruthers', ['#', 'Ferguson', 'T', 'rut', 'hers']), ('#SayNoToIslamophobia', ['#', 'Say', 'No', 'ToI', 'sla', 'moph', 'obi', 'a']), (\"#ErdoÄŸan's\", ['#', 'Er', 'do', 'ÄŸ', 'an', \"'\", 's']), ('#Lunacy', ['#', 'Lunacy']), ('#sick', ['#', 'sick']), ('#snipertime', ['#', 'sniper', 'time']), ('#AlQaida', ['#', 'Al', 'Q', 'a', 'ida']), ('#bogus', ['#', 'bogus']), ('#aweshit', ['#', 'awes', 'hit'])]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "# from time import *\n",
    "# begin_time = time()\n",
    "\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "#a list of words provided by NLTK\n",
    "words = set(nltk.corpus.words.words()) \n",
    "\n",
    "#Change the word list to lowercase\n",
    "lower_words = set([word.lower()  for word in words ]) \n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "#Since WordNetLemmatizer cannot use 'nltk.tag.pos_tag' directly, the output tag needs to be converted\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "\n",
    "\n",
    "def tokenize_hashtags(hashtags):\n",
    "    ###\n",
    "    # Your answer BEGINS HERE\n",
    "    ###\n",
    "    # a reversed version of the MaxMatch algorithm \n",
    "    hashtags_dic = dict()\n",
    "    #Go through every hashtags\n",
    "    for item in hashtags:\n",
    "        temp_item = item\n",
    "        position=0\n",
    "        max_match=[]\n",
    "        while len(item) > position:\n",
    "            #Perform lexical restoration on the input string\n",
    "            find_item = str(item[position:])\n",
    "            word=lemmatizer.lemmatize(find_item, pos = get_wordnet_pos(find_item)) \n",
    "            word = word.lower()\n",
    "            \n",
    "            if word in lower_words:\n",
    "                max_match.append(item[position:])\n",
    "                item=item[:position]\n",
    "                position = 0\n",
    "            elif len(item[position:]) == 1:\n",
    "                \n",
    "                max_match.append(item[position:])\n",
    "                item=item[:position]\n",
    "                position = 0\n",
    "\n",
    "            else:\n",
    "                #If it does not match, the string length is +1 and the previous step is repeated    \n",
    "                position+=1   \n",
    "        hashtags_dic[temp_item] = list(reversed(max_match)) \n",
    "\n",
    "    return hashtags_dic\n",
    "    ###\n",
    "    # Your answer ENDS HERE\n",
    "    ###\n",
    "\n",
    "\n",
    "tokenized_hashtags = tokenize_hashtags(hashtags)\n",
    "\n",
    "# end_time = time()\n",
    "# run_time = end_time-begin_time\n",
    "# print ('run_timeï¼š',run_time) \n",
    "\n",
    "print(list(tokenized_hashtags.items())[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For your testing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(tokenized_hashtags) == len(hashtags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 (1.0 mark)\n",
    "\n",
    "**Instructions**: Now that we have the tokenized hashtags, we need to go back and update the bag-of-words representation for each event.\n",
    "\n",
    "**Task**: Complete the ``update_event_bow(events)`` function. The function takes **a list of preprocessed events**, and for each event, it looks for every hashtag it has and updates the bag-of-words dictionary with the tokenized hashtag tokens. Note: you do not need to delete the counts of the original hashtags when updating the bag-of-words (e.g., if a document has \"#speakup\":2 in its bag-of-words representation, you do not need to delete this hashtag and its counts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of preprocessed rumour events = 500\n",
      "Number of preprocessed non-rumour events = 1000\n"
     ]
    }
   ],
   "source": [
    "def update_event_bow(events):\n",
    "    ###\n",
    "    # Your answer BEGINS HERE\n",
    "    ###\n",
    "    \n",
    "    \n",
    "    for number, event in enumerate(events):\n",
    "        temp_event = event.copy()\n",
    "        for word, frequency in temp_event.items():\n",
    "            if word.startswith(\"#\"):    \n",
    "                tokenized_hashtag = tokenized_hashtags[word]\n",
    "                for i in tokenized_hashtag:\n",
    "                    if i == '#':\n",
    "                        events[number][i] = 0\n",
    "                    events[number][i] += frequency\n",
    "                        \n",
    "                \n",
    "    return events\n",
    "    \n",
    "    ###\n",
    "    # Your answer ENDS HERE\n",
    "    ###\n",
    "            \n",
    "update_event_bow(preprocessed_rumour_events)\n",
    "update_event_bow(preprocessed_nonrumour_events)\n",
    "\n",
    "print(\"Number of preprocessed rumour events =\", len(preprocessed_rumour_events))\n",
    "print(\"Number of preprocessed non-rumour events =\", len(preprocessed_nonrumour_events))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification (4 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 (1.0 mark)\n",
    "\n",
    "**Instructions**: Here we are interested to do text classification, to predict, given a tweet and its reactions, whether it is a rumour or not. The task here is to create training, development and test partitions from the preprocessed events and convert the bag-of-words representation into feature vectors.\n",
    "\n",
    "**Task**: Using scikit-learn, create training, development and test partitions with a 60%/20%/20% ratio. Remember to preserve the ratio of rumour/non-rumour events for all your partitions. Next, turn the bag-of-words dictionary of each event into a feature vector, using scikit-learn `DictVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size = 27879\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "vectorizer = DictVectorizer()\n",
    "\n",
    "###\n",
    "# Your answer BEGINS HERE\n",
    "###\n",
    "\n",
    "#Mark all rumors as 1\n",
    "data_rumour_y = [1 for i in range(len(preprocessed_rumour_events))]\n",
    "#Mark all nonrumour as 0\n",
    "data_nonrumour_y = [0 for i in range(len(preprocessed_nonrumour_events))]\n",
    "\n",
    "#Merge rumor and non-rumor data\n",
    "data_x = preprocessed_rumour_events + preprocessed_nonrumour_events\n",
    "data_y = data_rumour_y+data_nonrumour_y\n",
    "\n",
    "#Divide the test set by 20%\n",
    "xtrain_and_xdev,xtest,ytrain_and_xdev,ytest=train_test_split(data_x,data_y,test_size=0.2,stratify=data_y)\n",
    "#Divide the remaining data into training sets and validation sets\n",
    "xtrain,xdev,ytrain,ydev=train_test_split(xtrain_and_xdev,ytrain_and_xdev,test_size=0.25,stratify=ytrain_and_xdev)\n",
    "\n",
    "\n",
    "xtrain = vectorizer.fit_transform(xtrain)\n",
    "xdev = vectorizer.transform(xdev)\n",
    "xtest = vectorizer.transform(xtest)\n",
    "\n",
    "    \n",
    "###\n",
    "# Your answer ENDS HERE\n",
    "###\n",
    "\n",
    "#If all the data were used to fit, the result would be 39703\n",
    "print(\"Vocabulary size =\", len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 (2.0 mark)\n",
    "\n",
    "**Instructions**: Now, let's build some classifiers. Here, we'll be comparing Naive Bayes and Logistic Regression. For each, you need to first find a good value for their main regularisation (hyper)parameters, which you should identify using the scikit-learn docs or other resources. Use the development set you created for this tuning process; do **not** use cross-validation in the training set, or involve the test set in any way. You don't need to show all your work, but you do need to print out the accuracy with enough different settings to strongly suggest you have found an optimal or near-optimal choice. We should not need to look at your code to interpret the output.\n",
    "\n",
    "**Task**: Implement two text classifiers: Naive Bayes and Logistic Regression. Tune the hyper-parameters of these classifiers and print the task performance for different hyper-parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_best_estimator_ LogisticRegression(C=0.3216080402010051, class_weight=None, dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=500, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\n",
      "LR_best_score 0.82\n",
      "\n",
      "LR_params [{'C': 0.1, 'max_iter': 500}, {'C': 0.12462311557788945, 'max_iter': 500}, {'C': 0.1492462311557789, 'max_iter': 500}, {'C': 0.17386934673366836, 'max_iter': 500}, {'C': 0.19849246231155782, 'max_iter': 500}, {'C': 0.22311557788944725, 'max_iter': 500}, {'C': 0.2477386934673367, 'max_iter': 500}, {'C': 0.2723618090452261, 'max_iter': 500}, {'C': 0.2969849246231156, 'max_iter': 500}, {'C': 0.3216080402010051, 'max_iter': 500}, {'C': 0.3462311557788945, 'max_iter': 500}, {'C': 0.37085427135678395, 'max_iter': 500}, {'C': 0.3954773869346734, 'max_iter': 500}, {'C': 0.4201005025125628, 'max_iter': 500}, {'C': 0.44472361809045224, 'max_iter': 500}, {'C': 0.4693467336683418, 'max_iter': 500}, {'C': 0.4939698492462312, 'max_iter': 500}, {'C': 0.5185929648241207, 'max_iter': 500}, {'C': 0.5432160804020101, 'max_iter': 500}, {'C': 0.5678391959798995, 'max_iter': 500}, {'C': 0.592462311557789, 'max_iter': 500}, {'C': 0.6170854271356784, 'max_iter': 500}, {'C': 0.6417085427135678, 'max_iter': 500}, {'C': 0.6663316582914574, 'max_iter': 500}, {'C': 0.6909547738693468, 'max_iter': 500}, {'C': 0.7155778894472362, 'max_iter': 500}, {'C': 0.7402010050251256, 'max_iter': 500}, {'C': 0.7648241206030151, 'max_iter': 500}, {'C': 0.7894472361809045, 'max_iter': 500}, {'C': 0.814070351758794, 'max_iter': 500}, {'C': 0.8386934673366835, 'max_iter': 500}, {'C': 0.8633165829145729, 'max_iter': 500}, {'C': 0.8879396984924623, 'max_iter': 500}, {'C': 0.9125628140703518, 'max_iter': 500}, {'C': 0.9371859296482412, 'max_iter': 500}, {'C': 0.9618090452261306, 'max_iter': 500}, {'C': 0.9864321608040202, 'max_iter': 500}, {'C': 1.0110552763819096, 'max_iter': 500}, {'C': 1.0356783919597992, 'max_iter': 500}, {'C': 1.0603015075376885, 'max_iter': 500}, {'C': 1.084924623115578, 'max_iter': 500}, {'C': 1.1095477386934676, 'max_iter': 500}, {'C': 1.1341708542713569, 'max_iter': 500}, {'C': 1.1587939698492464, 'max_iter': 500}, {'C': 1.1834170854271358, 'max_iter': 500}, {'C': 1.2080402010050253, 'max_iter': 500}, {'C': 1.2326633165829148, 'max_iter': 500}, {'C': 1.2572864321608042, 'max_iter': 500}, {'C': 1.2819095477386937, 'max_iter': 500}, {'C': 1.306532663316583, 'max_iter': 500}, {'C': 1.3311557788944726, 'max_iter': 500}, {'C': 1.3557788944723619, 'max_iter': 500}, {'C': 1.3804020100502514, 'max_iter': 500}, {'C': 1.405025125628141, 'max_iter': 500}, {'C': 1.4296482412060303, 'max_iter': 500}, {'C': 1.4542713567839198, 'max_iter': 500}, {'C': 1.4788944723618092, 'max_iter': 500}, {'C': 1.5035175879396987, 'max_iter': 500}, {'C': 1.5281407035175882, 'max_iter': 500}, {'C': 1.5527638190954776, 'max_iter': 500}, {'C': 1.577386934673367, 'max_iter': 500}, {'C': 1.6020100502512564, 'max_iter': 500}, {'C': 1.626633165829146, 'max_iter': 500}, {'C': 1.6512562814070353, 'max_iter': 500}, {'C': 1.6758793969849248, 'max_iter': 500}, {'C': 1.7005025125628144, 'max_iter': 500}, {'C': 1.7251256281407037, 'max_iter': 500}, {'C': 1.7497487437185932, 'max_iter': 500}, {'C': 1.7743718592964826, 'max_iter': 500}, {'C': 1.798994974874372, 'max_iter': 500}, {'C': 1.8236180904522614, 'max_iter': 500}, {'C': 1.848241206030151, 'max_iter': 500}, {'C': 1.8728643216080405, 'max_iter': 500}, {'C': 1.8974874371859298, 'max_iter': 500}, {'C': 1.9221105527638194, 'max_iter': 500}, {'C': 1.9467336683417087, 'max_iter': 500}, {'C': 1.9713567839195982, 'max_iter': 500}, {'C': 1.9959798994974878, 'max_iter': 500}, {'C': 2.020603015075377, 'max_iter': 500}, {'C': 2.0452261306532664, 'max_iter': 500}, {'C': 2.069849246231156, 'max_iter': 500}, {'C': 2.0944723618090455, 'max_iter': 500}, {'C': 2.119095477386935, 'max_iter': 500}, {'C': 2.143718592964824, 'max_iter': 500}, {'C': 2.1683417085427137, 'max_iter': 500}, {'C': 2.1929648241206032, 'max_iter': 500}, {'C': 2.2175879396984928, 'max_iter': 500}, {'C': 2.2422110552763823, 'max_iter': 500}, {'C': 2.2668341708542714, 'max_iter': 500}, {'C': 2.291457286432161, 'max_iter': 500}, {'C': 2.3160804020100505, 'max_iter': 500}, {'C': 2.34070351758794, 'max_iter': 500}, {'C': 2.3653266331658296, 'max_iter': 500}, {'C': 2.3899497487437187, 'max_iter': 500}, {'C': 2.4145728643216082, 'max_iter': 500}, {'C': 2.4391959798994978, 'max_iter': 500}, {'C': 2.4638190954773873, 'max_iter': 500}, {'C': 2.488442211055277, 'max_iter': 500}, {'C': 2.513065326633166, 'max_iter': 500}, {'C': 2.5376884422110555, 'max_iter': 500}, {'C': 2.562311557788945, 'max_iter': 500}, {'C': 2.5869346733668346, 'max_iter': 500}, {'C': 2.6115577889447237, 'max_iter': 500}, {'C': 2.636180904522613, 'max_iter': 500}, {'C': 2.6608040201005028, 'max_iter': 500}, {'C': 2.6854271356783923, 'max_iter': 500}, {'C': 2.710050251256282, 'max_iter': 500}, {'C': 2.734673366834171, 'max_iter': 500}, {'C': 2.7592964824120605, 'max_iter': 500}, {'C': 2.78391959798995, 'max_iter': 500}, {'C': 2.8085427135678396, 'max_iter': 500}, {'C': 2.833165829145729, 'max_iter': 500}, {'C': 2.857788944723618, 'max_iter': 500}, {'C': 2.8824120603015078, 'max_iter': 500}, {'C': 2.9070351758793973, 'max_iter': 500}, {'C': 2.931658291457287, 'max_iter': 500}, {'C': 2.9562814070351764, 'max_iter': 500}, {'C': 2.9809045226130655, 'max_iter': 500}, {'C': 3.005527638190955, 'max_iter': 500}, {'C': 3.0301507537688446, 'max_iter': 500}, {'C': 3.054773869346734, 'max_iter': 500}, {'C': 3.079396984924623, 'max_iter': 500}, {'C': 3.1040201005025128, 'max_iter': 500}, {'C': 3.1286432160804023, 'max_iter': 500}, {'C': 3.153266331658292, 'max_iter': 500}, {'C': 3.1778894472361814, 'max_iter': 500}, {'C': 3.2025125628140705, 'max_iter': 500}, {'C': 3.22713567839196, 'max_iter': 500}, {'C': 3.2517587939698496, 'max_iter': 500}, {'C': 3.276381909547739, 'max_iter': 500}, {'C': 3.3010050251256287, 'max_iter': 500}, {'C': 3.3256281407035178, 'max_iter': 500}, {'C': 3.3502512562814073, 'max_iter': 500}, {'C': 3.374874371859297, 'max_iter': 500}, {'C': 3.3994974874371864, 'max_iter': 500}, {'C': 3.424120603015076, 'max_iter': 500}, {'C': 3.448743718592965, 'max_iter': 500}, {'C': 3.4733668341708546, 'max_iter': 500}, {'C': 3.497989949748744, 'max_iter': 500}, {'C': 3.5226130653266337, 'max_iter': 500}, {'C': 3.5472361809045228, 'max_iter': 500}, {'C': 3.5718592964824123, 'max_iter': 500}, {'C': 3.596482412060302, 'max_iter': 500}, {'C': 3.6211055276381914, 'max_iter': 500}, {'C': 3.645728643216081, 'max_iter': 500}, {'C': 3.67035175879397, 'max_iter': 500}, {'C': 3.6949748743718596, 'max_iter': 500}, {'C': 3.719597989949749, 'max_iter': 500}, {'C': 3.7442211055276386, 'max_iter': 500}, {'C': 3.768844221105528, 'max_iter': 500}, {'C': 3.7934673366834173, 'max_iter': 500}, {'C': 3.818090452261307, 'max_iter': 500}, {'C': 3.8427135678391964, 'max_iter': 500}, {'C': 3.867336683417086, 'max_iter': 500}, {'C': 3.8919597989949755, 'max_iter': 500}, {'C': 3.9165829145728646, 'max_iter': 500}, {'C': 3.941206030150754, 'max_iter': 500}, {'C': 3.9658291457286436, 'max_iter': 500}, {'C': 3.990452261306533, 'max_iter': 500}, {'C': 4.015075376884422, 'max_iter': 500}, {'C': 4.039698492462311, 'max_iter': 500}, {'C': 4.064321608040201, 'max_iter': 500}, {'C': 4.0889447236180905, 'max_iter': 500}, {'C': 4.11356783919598, 'max_iter': 500}, {'C': 4.13819095477387, 'max_iter': 500}, {'C': 4.162814070351759, 'max_iter': 500}, {'C': 4.187437185929648, 'max_iter': 500}, {'C': 4.212060301507537, 'max_iter': 500}, {'C': 4.236683417085427, 'max_iter': 500}, {'C': 4.261306532663316, 'max_iter': 500}, {'C': 4.285929648241206, 'max_iter': 500}, {'C': 4.3105527638190955, 'max_iter': 500}, {'C': 4.335175879396985, 'max_iter': 500}, {'C': 4.3597989949748746, 'max_iter': 500}, {'C': 4.384422110552764, 'max_iter': 500}, {'C': 4.409045226130654, 'max_iter': 500}, {'C': 4.433668341708542, 'max_iter': 500}, {'C': 4.458291457286432, 'max_iter': 500}, {'C': 4.482914572864321, 'max_iter': 500}, {'C': 4.507537688442211, 'max_iter': 500}, {'C': 4.5321608040201005, 'max_iter': 500}, {'C': 4.55678391959799, 'max_iter': 500}, {'C': 4.5814070351758795, 'max_iter': 500}, {'C': 4.606030150753769, 'max_iter': 500}, {'C': 4.630653266331659, 'max_iter': 500}, {'C': 4.655276381909547, 'max_iter': 500}, {'C': 4.679899497487437, 'max_iter': 500}, {'C': 4.704522613065326, 'max_iter': 500}, {'C': 4.729145728643216, 'max_iter': 500}, {'C': 4.7537688442211055, 'max_iter': 500}, {'C': 4.778391959798995, 'max_iter': 500}, {'C': 4.8030150753768845, 'max_iter': 500}, {'C': 4.827638190954774, 'max_iter': 500}, {'C': 4.852261306532664, 'max_iter': 500}, {'C': 4.876884422110553, 'max_iter': 500}, {'C': 4.901507537688442, 'max_iter': 500}, {'C': 4.926130653266331, 'max_iter': 500}, {'C': 4.950753768844221, 'max_iter': 500}, {'C': 4.9753768844221105, 'max_iter': 500}, {'C': 5.0, 'max_iter': 500}]\n",
      "\n",
      "LR_test_score [0.81666667 0.81666667 0.81666667 0.80666667 0.80666667 0.81333333\n",
      " 0.81666667 0.81666667 0.81666667 0.82       0.81666667 0.81666667\n",
      " 0.81666667 0.81666667 0.82       0.82       0.82       0.82\n",
      " 0.82       0.82       0.81333333 0.81333333 0.81       0.81\n",
      " 0.81       0.81       0.81       0.81       0.81       0.81\n",
      " 0.80666667 0.80666667 0.80333333 0.8        0.8        0.8\n",
      " 0.8        0.8        0.79666667 0.79666667 0.79666667 0.79666667\n",
      " 0.79666667 0.79666667 0.79666667 0.79666667 0.79333333 0.79333333\n",
      " 0.79       0.79       0.79       0.79       0.79       0.79\n",
      " 0.79       0.79       0.79       0.79       0.79       0.79\n",
      " 0.79       0.79       0.79       0.79       0.79       0.79\n",
      " 0.79       0.79       0.79       0.79       0.79       0.79\n",
      " 0.79       0.79       0.79       0.79       0.79       0.79\n",
      " 0.79333333 0.79333333 0.79333333 0.79333333 0.79333333 0.79333333\n",
      " 0.79333333 0.79333333 0.79333333 0.79333333 0.79333333 0.79333333\n",
      " 0.79333333 0.79333333 0.79333333 0.79333333 0.79333333 0.79333333\n",
      " 0.79333333 0.79333333 0.79333333 0.79333333 0.79333333 0.79333333\n",
      " 0.79333333 0.79333333 0.79333333 0.79333333 0.79333333 0.79333333\n",
      " 0.79333333 0.79333333 0.79333333 0.79333333 0.79333333 0.79333333\n",
      " 0.79333333 0.79333333 0.79333333 0.79333333 0.79333333 0.79333333\n",
      " 0.79333333 0.79333333 0.79333333 0.79333333 0.79333333 0.79333333\n",
      " 0.79333333 0.79333333 0.79333333 0.79333333 0.79333333 0.79333333\n",
      " 0.79333333 0.79333333 0.79333333 0.79333333 0.79       0.79\n",
      " 0.79       0.79       0.79       0.79       0.79       0.79\n",
      " 0.79       0.79       0.79       0.79       0.79       0.79\n",
      " 0.79       0.79       0.79       0.79       0.79       0.79\n",
      " 0.79       0.79       0.79       0.79       0.79       0.79\n",
      " 0.79       0.79       0.79       0.79       0.79       0.79\n",
      " 0.79       0.79       0.78666667 0.78666667 0.78666667 0.78666667\n",
      " 0.78666667 0.78666667 0.78666667 0.78666667 0.78333333 0.78333333\n",
      " 0.78333333 0.78333333 0.78333333 0.78333333 0.78333333 0.78333333\n",
      " 0.78333333 0.78333333 0.78333333 0.78333333 0.78333333 0.78333333\n",
      " 0.78333333 0.78333333 0.78333333 0.78333333 0.78333333 0.78333333\n",
      " 0.78333333 0.78333333]\n",
      "\n",
      "________________________________________________________________________\n",
      "\n",
      "NB_best_estimator_ MultinomialNB(alpha=1.256281407035176, class_prior=None, fit_prior=True)\n",
      "\n",
      "NB_best_score 0.8433333333333334\n",
      "\n",
      "NB_params [{'alpha': 0.0}, {'alpha': 0.02512562814070352}, {'alpha': 0.05025125628140704}, {'alpha': 0.07537688442211056}, {'alpha': 0.10050251256281408}, {'alpha': 0.1256281407035176}, {'alpha': 0.15075376884422112}, {'alpha': 0.17587939698492464}, {'alpha': 0.20100502512562815}, {'alpha': 0.22613065326633167}, {'alpha': 0.2512562814070352}, {'alpha': 0.2763819095477387}, {'alpha': 0.30150753768844224}, {'alpha': 0.32663316582914576}, {'alpha': 0.35175879396984927}, {'alpha': 0.3768844221105528}, {'alpha': 0.4020100502512563}, {'alpha': 0.4271356783919598}, {'alpha': 0.45226130653266333}, {'alpha': 0.47738693467336685}, {'alpha': 0.5025125628140704}, {'alpha': 0.5276381909547739}, {'alpha': 0.5527638190954774}, {'alpha': 0.577889447236181}, {'alpha': 0.6030150753768845}, {'alpha': 0.628140703517588}, {'alpha': 0.6532663316582915}, {'alpha': 0.678391959798995}, {'alpha': 0.7035175879396985}, {'alpha': 0.7286432160804021}, {'alpha': 0.7537688442211056}, {'alpha': 0.7788944723618091}, {'alpha': 0.8040201005025126}, {'alpha': 0.8291457286432161}, {'alpha': 0.8542713567839196}, {'alpha': 0.8793969849246231}, {'alpha': 0.9045226130653267}, {'alpha': 0.9296482412060302}, {'alpha': 0.9547738693467337}, {'alpha': 0.9798994974874372}, {'alpha': 1.0050251256281408}, {'alpha': 1.0301507537688444}, {'alpha': 1.0552763819095479}, {'alpha': 1.0804020100502514}, {'alpha': 1.105527638190955}, {'alpha': 1.1306532663316584}, {'alpha': 1.155778894472362}, {'alpha': 1.1809045226130654}, {'alpha': 1.206030150753769}, {'alpha': 1.2311557788944725}, {'alpha': 1.256281407035176}, {'alpha': 1.2814070351758795}, {'alpha': 1.306532663316583}, {'alpha': 1.3316582914572865}, {'alpha': 1.35678391959799}, {'alpha': 1.3819095477386936}, {'alpha': 1.407035175879397}, {'alpha': 1.4321608040201006}, {'alpha': 1.4572864321608041}, {'alpha': 1.4824120603015076}, {'alpha': 1.5075376884422111}, {'alpha': 1.5326633165829147}, {'alpha': 1.5577889447236182}, {'alpha': 1.5829145728643217}, {'alpha': 1.6080402010050252}, {'alpha': 1.6331658291457287}, {'alpha': 1.6582914572864322}, {'alpha': 1.6834170854271358}, {'alpha': 1.7085427135678393}, {'alpha': 1.7336683417085428}, {'alpha': 1.7587939698492463}, {'alpha': 1.7839195979899498}, {'alpha': 1.8090452261306533}, {'alpha': 1.8341708542713568}, {'alpha': 1.8592964824120604}, {'alpha': 1.8844221105527639}, {'alpha': 1.9095477386934674}, {'alpha': 1.934673366834171}, {'alpha': 1.9597989949748744}, {'alpha': 1.984924623115578}, {'alpha': 2.0100502512562817}, {'alpha': 2.035175879396985}, {'alpha': 2.0603015075376887}, {'alpha': 2.085427135678392}, {'alpha': 2.1105527638190957}, {'alpha': 2.1356783919597992}, {'alpha': 2.1608040201005028}, {'alpha': 2.1859296482412063}, {'alpha': 2.21105527638191}, {'alpha': 2.2361809045226133}, {'alpha': 2.261306532663317}, {'alpha': 2.2864321608040203}, {'alpha': 2.311557788944724}, {'alpha': 2.3366834170854274}, {'alpha': 2.361809045226131}, {'alpha': 2.3869346733668344}, {'alpha': 2.412060301507538}, {'alpha': 2.4371859296482414}, {'alpha': 2.462311557788945}, {'alpha': 2.4874371859296485}, {'alpha': 2.512562814070352}, {'alpha': 2.5376884422110555}, {'alpha': 2.562814070351759}, {'alpha': 2.5879396984924625}, {'alpha': 2.613065326633166}, {'alpha': 2.6381909547738696}, {'alpha': 2.663316582914573}, {'alpha': 2.6884422110552766}, {'alpha': 2.71356783919598}, {'alpha': 2.7386934673366836}, {'alpha': 2.763819095477387}, {'alpha': 2.7889447236180906}, {'alpha': 2.814070351758794}, {'alpha': 2.8391959798994977}, {'alpha': 2.864321608040201}, {'alpha': 2.8894472361809047}, {'alpha': 2.9145728643216082}, {'alpha': 2.9396984924623117}, {'alpha': 2.9648241206030153}, {'alpha': 2.9899497487437188}, {'alpha': 3.0150753768844223}, {'alpha': 3.040201005025126}, {'alpha': 3.0653266331658293}, {'alpha': 3.090452261306533}, {'alpha': 3.1155778894472363}, {'alpha': 3.14070351758794}, {'alpha': 3.1658291457286434}, {'alpha': 3.190954773869347}, {'alpha': 3.2160804020100504}, {'alpha': 3.241206030150754}, {'alpha': 3.2663316582914574}, {'alpha': 3.291457286432161}, {'alpha': 3.3165829145728645}, {'alpha': 3.341708542713568}, {'alpha': 3.3668341708542715}, {'alpha': 3.391959798994975}, {'alpha': 3.4170854271356785}, {'alpha': 3.442211055276382}, {'alpha': 3.4673366834170856}, {'alpha': 3.492462311557789}, {'alpha': 3.5175879396984926}, {'alpha': 3.542713567839196}, {'alpha': 3.5678391959798996}, {'alpha': 3.592964824120603}, {'alpha': 3.6180904522613067}, {'alpha': 3.64321608040201}, {'alpha': 3.6683417085427137}, {'alpha': 3.693467336683417}, {'alpha': 3.7185929648241207}, {'alpha': 3.7437185929648242}, {'alpha': 3.7688442211055277}, {'alpha': 3.7939698492462313}, {'alpha': 3.819095477386935}, {'alpha': 3.8442211055276383}, {'alpha': 3.869346733668342}, {'alpha': 3.8944723618090453}, {'alpha': 3.919597989949749}, {'alpha': 3.9447236180904524}, {'alpha': 3.969849246231156}, {'alpha': 3.9949748743718594}, {'alpha': 4.020100502512563}, {'alpha': 4.045226130653266}, {'alpha': 4.07035175879397}, {'alpha': 4.0954773869346734}, {'alpha': 4.120603015075377}, {'alpha': 4.1457286432160805}, {'alpha': 4.170854271356784}, {'alpha': 4.1959798994974875}, {'alpha': 4.2211055276381915}, {'alpha': 4.2462311557788945}, {'alpha': 4.2713567839195985}, {'alpha': 4.296482412060302}, {'alpha': 4.3216080402010055}, {'alpha': 4.346733668341709}, {'alpha': 4.371859296482413}, {'alpha': 4.396984924623116}, {'alpha': 4.42211055276382}, {'alpha': 4.447236180904523}, {'alpha': 4.472361809045227}, {'alpha': 4.49748743718593}, {'alpha': 4.522613065326634}, {'alpha': 4.547738693467337}, {'alpha': 4.572864321608041}, {'alpha': 4.597989949748744}, {'alpha': 4.623115577889448}, {'alpha': 4.648241206030151}, {'alpha': 4.673366834170855}, {'alpha': 4.698492462311558}, {'alpha': 4.723618090452262}, {'alpha': 4.748743718592965}, {'alpha': 4.773869346733669}, {'alpha': 4.798994974874372}, {'alpha': 4.824120603015076}, {'alpha': 4.849246231155779}, {'alpha': 4.874371859296483}, {'alpha': 4.899497487437186}, {'alpha': 4.92462311557789}, {'alpha': 4.949748743718593}, {'alpha': 4.974874371859297}, {'alpha': 5.0}]\n",
      "\n",
      "NB_test_score [0.78333333 0.83333333 0.83666667 0.84       0.82666667 0.82\n",
      " 0.81333333 0.81       0.81       0.81333333 0.81333333 0.82\n",
      " 0.82       0.82       0.82       0.82       0.82       0.81666667\n",
      " 0.81666667 0.81666667 0.81666667 0.81333333 0.81666667 0.82\n",
      " 0.82333333 0.82333333 0.82666667 0.82666667 0.82666667 0.82666667\n",
      " 0.82666667 0.82666667 0.83       0.83       0.83       0.83333333\n",
      " 0.83333333 0.83666667 0.83666667 0.84       0.83666667 0.83333333\n",
      " 0.84       0.83333333 0.83       0.83       0.83333333 0.83666667\n",
      " 0.84       0.84       0.84333333 0.84333333 0.83666667 0.82333333\n",
      " 0.82       0.82       0.82       0.82       0.82       0.82\n",
      " 0.81666667 0.81333333 0.81333333 0.81333333 0.81       0.81\n",
      " 0.81       0.81       0.81       0.81333333 0.81       0.81\n",
      " 0.80666667 0.80333333 0.80333333 0.8        0.80333333 0.80333333\n",
      " 0.80333333 0.80333333 0.80333333 0.8        0.8        0.79666667\n",
      " 0.79666667 0.79666667 0.8        0.8        0.8        0.8\n",
      " 0.8        0.8        0.8        0.79666667 0.79666667 0.79666667\n",
      " 0.79666667 0.79333333 0.79333333 0.79       0.79       0.79\n",
      " 0.79333333 0.79333333 0.79333333 0.79333333 0.79333333 0.79333333\n",
      " 0.78666667 0.78666667 0.78666667 0.78666667 0.78666667 0.78333333\n",
      " 0.78333333 0.78333333 0.78333333 0.78333333 0.78333333 0.78333333\n",
      " 0.78333333 0.78       0.78       0.78       0.77666667 0.77666667\n",
      " 0.77333333 0.77333333 0.77       0.77333333 0.77333333 0.77333333\n",
      " 0.77333333 0.77333333 0.77       0.77       0.77       0.77\n",
      " 0.77       0.77333333 0.77       0.77       0.76666667 0.76666667\n",
      " 0.76666667 0.76666667 0.76666667 0.76666667 0.76666667 0.76666667\n",
      " 0.76666667 0.76666667 0.76666667 0.76666667 0.76666667 0.76666667\n",
      " 0.76666667 0.76666667 0.77       0.77       0.76666667 0.76666667\n",
      " 0.76666667 0.76666667 0.76333333 0.76333333 0.76333333 0.76333333\n",
      " 0.76333333 0.76333333 0.75666667 0.76       0.76       0.76\n",
      " 0.76       0.76       0.76       0.76       0.76       0.76\n",
      " 0.76       0.76       0.76       0.75666667 0.75333333 0.75333333\n",
      " 0.74666667 0.74333333 0.74333333 0.74333333 0.74       0.74\n",
      " 0.74       0.74       0.74       0.74       0.74333333 0.74333333\n",
      " 0.74333333 0.74333333]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection  import GridSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "from scipy.sparse import  vstack\n",
    "###\n",
    "# Your answer BEGINS HERE\n",
    "###\n",
    "\n",
    "#Define model\n",
    "NB = MultinomialNB()\n",
    "LR = LogisticRegression()\n",
    "\n",
    "#handle dataï¼Œmerge training set and validation set\n",
    "combine_xtrain = vstack((xtrain,xdev))\n",
    "combine_ytrain = ytrain+ydev\n",
    "\n",
    "#Initialize all index to 0,0 to represent the first round of the validation set\n",
    "test_fold = np.zeros(combine_xtrain.shape[0])  \n",
    "\n",
    "#Set the corresponding index of the training set to -1, indicating that it will never be divided into the verification set\n",
    "test_fold[:xtrain.shape[0]] = -1    \n",
    "\n",
    "#Provides train/dev indices to split data into train/dev sets\n",
    "ps = PredefinedSplit(test_fold=test_fold)  \n",
    "\n",
    "#Set the parameters to be searched by linear regression\n",
    "LR_param_grid = [\n",
    "  {'C': np.linspace(0.1, 5, 200),\"max_iter\":[500] }\n",
    " ]\n",
    "\n",
    "#use GridSearchCV to find the best param, cross-validation was not used because the training set and validation set were fixed\n",
    "#Initialize the GridSearch\n",
    "LR_grid_search = GridSearchCV(LR,LR_param_grid,n_jobs=-1,cv=ps,scoring='accuracy')\n",
    "LR_grid_search.fit(combine_xtrain, combine_ytrain)\n",
    "\n",
    "\n",
    "#Set the parameters to be searched by MultinomialNB\n",
    "NB_param_grid = [\n",
    "  {'alpha': np.linspace(0, 5, 200)}\n",
    " ]\n",
    "NB_grid_search = GridSearchCV(NB,NB_param_grid,n_jobs=-1,cv=ps,scoring='accuracy')\n",
    "NB_grid_search.fit(combine_xtrain, combine_ytrain)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"LR_best_estimator_\",LR_grid_search.best_estimator_)\n",
    "print()\n",
    "print(\"LR_best_score\",LR_grid_search.best_score_)\n",
    "print()\n",
    "print(\"LR_params\",LR_grid_search.cv_results_[\"params\"])\n",
    "print()\n",
    "print(\"LR_test_score\",LR_grid_search.cv_results_[\"split0_test_score\"])\n",
    "print()\n",
    "\n",
    "print(\"________________________________________________________________________\")\n",
    "print()\n",
    "print(\"NB_best_estimator_\",NB_grid_search.best_estimator_)\n",
    "print()\n",
    "print(\"NB_best_score\",NB_grid_search.best_score_)\n",
    "print()\n",
    "print(\"NB_params\",NB_grid_search.cv_results_[\"params\"])\n",
    "print()\n",
    "print(\"NB_test_score\",NB_grid_search.cv_results_[\"split0_test_score\"])\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "###\n",
    "# Your answer ENDS HERE\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB_best_estimator_ MultinomialNB(alpha=1.256281407035176, class_prior=None, fit_prior=True)\n",
      "\n",
      "NB_best_score 0.8433333333333334\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#draw\n",
    "import matplotlib.pyplot as plt\n",
    "x = [alpha['alpha']  for alpha in NB_grid_search.cv_results_[\"params\"]]\n",
    "y = [ score for score in NB_grid_search.cv_results_[\"split0_test_score\"] ]\n",
    "plt.figure()\n",
    "plt.plot(x,y)\n",
    "plt.xlabel('Params-Alpha')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('MultinomialNB')\n",
    "\n",
    "print(\"NB_best_estimator_\",NB_grid_search.best_estimator_)\n",
    "print()\n",
    "print(\"NB_best_score\",NB_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_best_estimator_ LogisticRegression(C=0.3216080402010051, class_weight=None, dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=500, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\n",
      "LR_best_score 0.82\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = [C['C']  for C in LR_grid_search.cv_results_[\"params\"]]\n",
    "y = [ score for score in LR_grid_search.cv_results_[\"split0_test_score\"] ]\n",
    "plt.figure()\n",
    "plt.plot(x,y)\n",
    "plt.xlabel('Params-C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('LogisticRegression')\n",
    "\n",
    "\n",
    "print(\"LR_best_estimator_\",LR_grid_search.best_estimator_)\n",
    "print()\n",
    "print(\"LR_best_score\",LR_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7 (1.0 mark)\n",
    "\n",
    "**Instructions**: Using the best settings you have found, compare the two classifiers based on performance in the test set. Print out both accuracy and macro-averaged F-score for each classifier. Be sure to label your output.\n",
    "\n",
    "**Task**: Compute test performance in terms of accuracy and macro-averaged F-score for both Naive Bayes and Logistic Regression, using optimal hyper-parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_test_result:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       200\n",
      "           1       0.75      0.61      0.67       100\n",
      "\n",
      "    accuracy                           0.80       300\n",
      "   macro avg       0.79      0.76      0.77       300\n",
      "weighted avg       0.80      0.80      0.80       300\n",
      "\n",
      "NB_test_result:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       200\n",
      "           1       0.76      0.73      0.74       100\n",
      "\n",
      "    accuracy                           0.83       300\n",
      "   macro avg       0.81      0.81      0.81       300\n",
      "weighted avg       0.83      0.83      0.83       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# Your answer BEGINS HERE\n",
    "###\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Define the model using the best parameters\n",
    "NB_best_params = MultinomialNB(alpha=NB_grid_search.best_params_['alpha'])\n",
    "LR_best_params = LogisticRegression(C=LR_grid_search.best_params_['C'],max_iter=LR_grid_search.best_params_['max_iter'])\n",
    "\n",
    "#Use the training set to train the model\n",
    "LR_best_params.fit(combine_xtrain, combine_ytrain)\n",
    "NB_best_params.fit(combine_xtrain, combine_ytrain)\n",
    "\n",
    "#Using test sets to predict categories\n",
    "LR_y_pred = LR_best_params.predict(xtest)\n",
    "NB_y_pred = NB_best_params.predict(xtest)\n",
    "\n",
    "#Print the performance on the test sets\n",
    "print(\"LR_test_result:\\n\",classification_report(ytest, LR_y_pred))\n",
    "print(\"NB_test_result:\\n\",classification_report(ytest, NB_y_pred))\n",
    "\n",
    "\n",
    "    \n",
    "###\n",
    "# Your answer ENDS HERE\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
